{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRESIDENT', 'HARRY', 'S', 'TRUMAN', 'S', 'ADDRESS', 'BEFORE', 'A', 'JOINT', 'SESSION', 'OF', 'THE', 'CONGRESS', 'April', 'Mr', 'Speaker', 'Mr', 'President', 'Members', 'of', 'the', 'Congress', 'It', 'is', 'with', 'a', 'heavy', 'heart', 'that', 'I']\n"
     ]
    }
   ],
   "source": [
    "# filter non-alpha\n",
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "print(words[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRESIDENT', 'HARRY', 'TRUMAN', 'ADDRESS', 'JOINT', 'SESSION', 'CONGRESS', 'April', 'Mr', 'Speaker', 'Mr', 'President', 'Members', 'Congress', 'heavy', 'heart', 'stand', 'friends', 'colleagues', 'Congress', 'United', 'States', 'yesterday', 'laid', 'rest', 'mortal', 'remains', 'beloved', 'President', 'Franklin']\n"
     ]
    }
   ],
   "source": [
    "# filter stop words\n",
    "words = [w for w in words if w.lower() not in stop_words]\n",
    "print(words[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a tokenized list of words\n",
    "words2 = nltk.word_tokenize(nltk.corpus.state_union.raw())\n",
    "# should use this with my essays in OkCupid project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Frequency Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"For some quick analysis, creating a corpus could be overkill. If all you need is a word list, there are simpler ways to achieve that goal.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a frequency distribution is a table which tells you how often a word appears in a body of text.\n",
    "words = nltk.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 2), ('a', 2), ('.', 2)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", a . \n",
      "2 2 2 \n"
     ]
    }
   ],
   "source": [
    "fd.tabulate(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.8012}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sia.polarity_scores(\"Wow, NLTK is really powerful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [t.replace(\"://\", \"//\") for t in nltk.corpus.twitter_samples.strings()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hopeless for tmr :(\n",
      "-0.7096\n",
      "Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\n",
      "-0.3425\n",
      "@Hegelbon That heart sliding into the waste basket. :(\n",
      "-0.6908\n",
      "“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\n",
      "\n",
      "Me too\n",
      "-0.765\n",
      "Dang starting next week I have \"work\" :(\n",
      "-0.4404\n",
      "oh god, my babies' faces :( https//t.co/9fcwGvaki0\n",
      "-0.2023\n",
      "@RileyMcDonough make me smile :((\n",
      "0.3612\n",
      "@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http//t.co/XvmTUikWln\n",
      "-0.7003\n",
      "why?:(\"@tahuodyy: sialan:( https//t.co/Hv1i0xcrL2\"\n",
      "0.0\n",
      "Athabasca glacier was there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http//t.co/dZZdqmf7Cz\n",
      "-0.3612\n",
      "I have a really good m&amp;g idea but I'm never going to meet them :(((\n",
      "0.2724\n",
      "@Rampageinthebox mare ivan :(\n",
      "-0.4404\n",
      "@SophiaMascardo happy trip, keep safe. see you soon :* :(\n",
      "0.802\n",
      "I'm so tired hahahah :(\n",
      "-0.7474\n",
      "@GrumpyCockney With knee replacements they get you up &amp; about the same day. :-(   Ouch.\n",
      "-0.3612\n",
      "relate to the \"sweet n' sour\" kind of \"bi-polar\" people in your life... cuz my life... is FULL of them... :(\n",
      "0.0258\n",
      "@aysegul_k pleasse :(\n",
      "-0.4404\n",
      "@SexyKalamo im not sure tho :(\n",
      "0.1139\n",
      "I feel stupid\n",
      "I just can't seem to grasp the basics of digital painting and nothing I've been researching is helping any :(\n",
      "-0.6249\n",
      "Good Lord. :( https//t.co/nC9LkYUUvO\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets[0:20]:\n",
    "    print(tweet)\n",
    "    print(sia.polarity_scores(tweet)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
