{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use PCA to reduce dimensionality of religion/ pets/ etc?\n",
    "# if I do this, can I map for prediction\n",
    "# create tone of essays and see if they correlate (PCA here?)\n",
    "# simplify the over-expressed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('profiles.csv')\n",
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
       "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
       "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
       "       'religion', 'sex', 'sign', 'smokes', 'speaks', 'status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHEncode m/f\n",
    "\n",
    "# break off column to OHE - this is done to avoid renaming all of the passthrough columns\n",
    "temp_df = df1[['sex']]\n",
    "\n",
    "# OHE encode \n",
    "transformer = make_column_transformer((OneHotEncoder(), ['sex']), remainder = 'passthrough', sparse_threshold=0)\n",
    "transformed = transformer.fit_transform(temp_df)\n",
    "transformed_df = pd.DataFrame(transformed, columns=transformer.get_feature_names_out())\n",
    "\n",
    "# rename the hot mess of column names that come from onehotencoder\n",
    "col_names = {'onehotencoder__sex_f': 'f', 'onehotencoder__sex_m': 'm'}\n",
    "transformed_df.rename(columns = col_names, inplace = True)\n",
    "\n",
    "# reassemble and reorder the df\n",
    "df1 = pd.concat([df1, transformed_df], axis=1)\n",
    "df1 = df1[['age', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'essay0',\n",
    "       'essay1', 'essay2', 'essay3', 'essay4', 'essay5', 'essay6', 'essay7',\n",
    "       'essay8', 'essay9', 'ethnicity', 'height', 'income', 'job',\n",
    "       'last_online', 'location', 'offspring', 'orientation', 'pets',\n",
    "       'religion', 'sex', 'f', 'm', 'sign', 'smokes', 'speaks', 'status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHEncode body_type\n",
    "# I would love to encode the nan's as 'rather not say' but I better not as they could arise from other issues (web/ UI errors)\n",
    "\n",
    "# isolate column for ohe\n",
    "body_temp_df = df1[['body_type']]\n",
    "\n",
    "# ohe now treats nan's as their own category https://stackoverflow.com/a/72379323\n",
    "\n",
    "# OHE encode \n",
    "b_transformer = make_column_transformer((OneHotEncoder(), ['body_type']), remainder = 'passthrough', sparse_threshold = 0)\n",
    "b_transformed = b_transformer.fit_transform(body_temp_df)\n",
    "b_transformed_df = pd.DataFrame(b_transformed, columns=b_transformer.get_feature_names_out())\n",
    "# rename the hot mess of column names that come from onehotencoder\n",
    "b_transformed_df = b_transformed_df.rename(columns=lambda x: re.sub('onehotencoder__','',x))\n",
    "\n",
    "# reassemble and reorder the df\n",
    "df1 = pd.concat([df1, b_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHEncode diet variables\n",
    "\n",
    "# isolate column for ohe\n",
    "diet_df = df1[['diet']]\n",
    "\n",
    "# OHE encode\n",
    "diet_transformer = make_column_transformer((OneHotEncoder(), ['diet']), remainder = 'passthrough', sparse_threshold = 0)\n",
    "diet_transformed = diet_transformer.fit_transform(diet_df)\n",
    "diet_transformed_df = pd.DataFrame(diet_transformed, columns = diet_transformer.get_feature_names_out())\n",
    "                                           \n",
    "# rename\n",
    "diet_transformed_df = diet_transformed_df.rename(columns = lambda x: re.sub('onehotencoder__', '', x))\n",
    "\n",
    "# combine dfs\n",
    "df1 = pd.concat([df1, diet_transformed_df], axis = 1)\n",
    "               \n",
    "# review\n",
    "# df1.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create diet strictness measure\n",
    "\n",
    "# build decision function for apply\n",
    "def diet_to_cat(x):\n",
    "    if 'anything' in x: return 0\n",
    "    elif 'strictly' in x: return 3\n",
    "    elif 'mostly' in x: return 1\n",
    "    else: return 2\n",
    "\n",
    "# get rid of nan's to avoid float error\n",
    "df1['diet'].fillna('', inplace=True)\n",
    "\n",
    "# cast as string to avoid object\n",
    "df['diet'] = df['diet'].astype('str')\n",
    "\n",
    "# create numeric variable\n",
    "df1['diet_strictness'] = df1['diet'].apply(diet_to_cat)\n",
    "\n",
    "# define as categorical, ordered data\n",
    "diet_temp = pd.Categorical(df1['diet_strictness'], ordered=True, categories=[0, 1, 2, 3])\n",
    "\n",
    "# replace data in df\n",
    "df1['diet_strictness'] = diet_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='drinks', ylabel='count'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# would be interesting to view the percentages of male and female at the ends of this distribution (desperately/ not at all)\n",
    "sns.countplot(x = df1['drinks'], data = df1, hue = 'sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHEncode drinks\n",
    "\n",
    "# isolate column for ohe\n",
    "drinks_df = df1[['drinks']]\n",
    "\n",
    "# ohe now treats nan's as their own category https://stackoverflow.com/a/72379323\n",
    "\n",
    "# OHE encode \n",
    "drinks_transformer = make_column_transformer((OneHotEncoder(), ['drinks']), remainder = 'passthrough', sparse_threshold = 0)\n",
    "drinks_transformed = drinks_transformer.fit_transform(drinks_df)\n",
    "drinks_transformed_df = pd.DataFrame(drinks_transformed, columns=drinks_transformer.get_feature_names_out())\n",
    "# rename the hot mess of column names that come from onehotencoder\n",
    "drinks_transformed_df = drinks_transformed_df.rename(columns=lambda x: re.sub('onehotencoder__','',x))\n",
    "\n",
    "# reassemble and reorder the df\n",
    "df1 = pd.concat([df1, drinks_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHEncode drugs\n",
    "\n",
    "# isolate column for ohe\n",
    "drugs_df = df1[['drugs']]\n",
    "\n",
    "# ohe now treats nan's as their own category https://stackoverflow.com/a/72379323\n",
    "\n",
    "# OHE encode \n",
    "drugs_transformer = make_column_transformer((OneHotEncoder(), ['drugs']), remainder = 'passthrough', sparse_threshold = 0)\n",
    "drugs_transformed = drugs_transformer.fit_transform(drugs_df)\n",
    "drugs_transformed_df = pd.DataFrame(drugs_transformed, columns=drugs_transformer.get_feature_names_out())\n",
    "# rename the hot mess of column names that come from onehotencoder\n",
    "drugs_transformed_df = drugs_transformed_df.rename(columns=lambda x: re.sub('onehotencoder__','',x))\n",
    "\n",
    "# reassemble and reorder the df\n",
    "df1 = pd.concat([df1, drugs_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehotencode education\n",
    "\n",
    "# isolate column for ohe\n",
    "education_df = df1[['education']]\n",
    "\n",
    "# ohe now treats nan's as their own category https://stackoverflow.com/a/72379323\n",
    "\n",
    "# OHE encode \n",
    "education_transformer = make_column_transformer((OneHotEncoder(), ['education']), remainder = 'passthrough', sparse_threshold = 0)\n",
    "education_transformed = education_transformer.fit_transform(education_df)\n",
    "education_transformed_df = pd.DataFrame(education_transformed, columns=education_transformer.get_feature_names_out())\n",
    "# rename the hot mess of column names that come from onehotencoder\n",
    "education_transformed_df = education_transformed_df.rename(columns=lambda x: re.sub('onehotencoder__','',x))\n",
    "\n",
    "# reassemble and reorder the df\n",
    "df1 = pd.concat([df1, education_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode ethnicity after filtering by 'primary' ethnicity\n",
    "\n",
    "df1['ethnicity'].fillna('', inplace = True)\n",
    "\n",
    "def primary_ethnicity(x):\n",
    "    split_string = x.split(', ')\n",
    "    primary_ethnicity = split_string[0]\n",
    "    return primary_ethnicity\n",
    "\n",
    "df1['primary_ethnicity'] = df1['ethnicity'].apply(primary_ethnicity)\n",
    "\n",
    "# onehotencode primary_ethnicity\n",
    "\n",
    "# isolate column for ohe\n",
    "primary_ethnicity_df = df1[['primary_ethnicity']]\n",
    "\n",
    "# ohe now treats nan's as their own category https://stackoverflow.com/a/72379323\n",
    "\n",
    "# OHE encode \n",
    "primary_ethnicity_transformer = make_column_transformer((OneHotEncoder(), ['primary_ethnicity']), remainder = 'passthrough', sparse_threshold = 0)\n",
    "primary_ethnicity_transformed = primary_ethnicity_transformer.fit_transform(primary_ethnicity_df)\n",
    "primary_ethnicity_transformed_df = pd.DataFrame(primary_ethnicity_transformed, columns=primary_ethnicity_transformer.get_feature_names_out())\n",
    "# rename the hot mess of column names that come from onehotencoder\n",
    "primary_ethnicity_transformed_df = primary_ethnicity_transformed_df.rename(columns=lambda x: re.sub('onehotencoder__','',x))\n",
    "\n",
    "# reassemble and reorder the df\n",
    "df1 = pd.concat([df1, primary_ethnicity_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 'reported income' variable\n",
    "df1['reported_income'] = df1['income'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "# create income bins with np.nan for non-reporters\n",
    "df1['income_bins_w_nan'] = df1['income'].apply(lambda x: 3 if (x>=500000 and x<=1000000) \n",
    "                                              else 2 if (x>=100000 and x<=250000)\n",
    "                                              else 1 if (x<250000 and x>0)\n",
    "                                              else np.nan)\n",
    "\n",
    "# create income bins with 0 for non-reporters\n",
    "df1['income_bins'] = df1['income'].apply(lambda x: 3 if (x>=500000 and x<=1000000) \n",
    "                                              else 2 if (x>=100000 and x<=250000)\n",
    "                                              else 1 if (x<250000 and x>0)\n",
    "                                              else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove html chars from dataframe\n",
    "df1.replace(r'''<\\/?\\w+((\\s+\\w+(\\s*=\\s*(?:\".*?\"|'.*?'|[^'\">\\s]+))?)+\\s*|\\s*)\\/?>''', \" \", regex=True, inplace=True)\n",
    "\n",
    "#remove URL items from dataframe\n",
    "df1.replace(r'''[-a-zA-Z0-9@:%_\\+.~#?&//=]{2,256}\\.[a-z]{2,4}\\b(\\/[-a-zA-Z0-9@:%_\\+.~#?&//=]*)?''', \" \", regex=True, inplace=True)\n",
    "\n",
    "# remove newlines from dataframe\n",
    "df1.replace(r\"\\n\", \" \", regex=True, inplace=True)\n",
    "\n",
    "# remove char refs\n",
    "df1.replace(r\"&amp;\", \"&\", regex=True, inplace=True)\n",
    "df1.replace(r\"&rsquo;\", \"'\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a bio feature that combines all essays\n",
    "essay_list = [\"essay\" + str(i) for i in range(0,10)]\n",
    "df1['biography'] = df1[essay_list].apply(lambda x: x + ' ').fillna(' ').sum(axis=1)\n",
    "df1['biography'].replace(r\"\\s+\", \" \", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentiment indicator column\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# import stop words\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# process bio and estimate sentiment\n",
    "def get_sentiment(x):\n",
    "    # tokenize biography text\n",
    "    bio_text = nltk.word_tokenize(x)\n",
    "    \n",
    "    # keep only alpha characters\n",
    "    bio_words = [w for w in bio_text if w.isalpha()]\n",
    "    \n",
    "    # filter stop words\n",
    "    bio_nonstop_words = [w for w in bio_words if w.lower() not in stop_words]\n",
    "    \n",
    "    # create string for sentiment analysis\n",
    "    bio_nonstop_words = ' '.join(bio_nonstop_words)\n",
    "    \n",
    "    # estimate sentiment\n",
    "    bio_sent = sia.polarity_scores(bio_nonstop_words)\n",
    "    \n",
    "    # return sentiment\n",
    "    return bio_sent['compound']\n",
    "\n",
    "df1['bio_sentiment'] = df1['biography'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15, 12))\n",
    "# sns.histplot(data=df1, x='bio_sentiment', kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Columns: 148 entries, age to job_nan\n",
      "dtypes: category(1), float64(91), int64(4), object(30), uint8(22)\n",
      "memory usage: 58.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "job_dummies = pd.get_dummies(df1['job'], prefix='job', prefix_sep='_', dummy_na=True, drop_first=False)\n",
    "df1 = pd.concat([df1, job_dummies], axis=1)\n",
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Columns: 164 entries, age to offspring_nan\n",
      "dtypes: category(1), float64(91), int64(4), object(30), uint8(38)\n",
      "memory usage: 59.4+ MB\n"
     ]
    }
   ],
   "source": [
    "offspring_dummies = pd.get_dummies(df1['offspring'], prefix='offspring',  prefix_sep='_', dummy_na=True, drop_first=False)\n",
    "df1 = pd.concat([df1, offspring_dummies], axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Columns: 168 entries, age to orientation_nan\n",
      "dtypes: category(1), float64(91), int64(4), object(30), uint8(42)\n",
      "memory usage: 59.6+ MB\n"
     ]
    }
   ],
   "source": [
    "orientation_dummies = pd.get_dummies(df1['orientation'], prefix='orientation',  prefix_sep='_', dummy_na=True, drop_first=False)\n",
    "df1 = pd.concat([df1, orientation_dummies], axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Columns: 184 entries, age to pets_nan\n",
      "dtypes: category(1), float64(91), int64(4), object(30), uint8(58)\n",
      "memory usage: 60.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pets_dummies = pd.get_dummies(df1['pets'], prefix='pets',  prefix_sep='_', dummy_na=True, drop_first=False)\n",
    "df1 = pd.concat([df1, pets_dummies], axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create measure of religious fervor\n",
    "\n",
    "# build decision function for apply\n",
    "def religion_to_cat(x):\n",
    "    if 'laughing about it' in x: return 0\n",
    "    elif 'not too serious about it' in x: return 1\n",
    "    elif 'somewhat serious about it' in x: return 3\n",
    "    elif 'very serious about it' in x: return 4\n",
    "    else: return 2\n",
    "\n",
    "# get rid of nan's to avoid float error\n",
    "df1['religion'].fillna('', inplace=True)\n",
    "\n",
    "# cast as string to avoid object\n",
    "df['religion'] = df['religion'].astype('str')\n",
    "\n",
    "# create numeric variable\n",
    "df1['rel_fervor'] = df1['religion'].apply(religion_to_cat)\n",
    "\n",
    "# define as categorical, ordered data\n",
    "religion_temp = pd.Categorical(df1['rel_fervor'], ordered=True, categories=[0, 1, 2, 3, 4])\n",
    "\n",
    "# replace data in df\n",
    "df1['rel_fervor'] = religion_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Columns: 191 entries, age to smokes_nan\n",
      "dtypes: category(2), float64(91), int64(4), object(30), uint8(64)\n",
      "memory usage: 60.9+ MB\n"
     ]
    }
   ],
   "source": [
    "smokes_dummies = pd.get_dummies(df1['smokes'], prefix='smokes',  prefix_sep='_', dummy_na=True, drop_first=False)\n",
    "df1 = pd.concat([df1, smokes_dummies], axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Columns: 197 entries, age to status_nan\n",
      "dtypes: category(2), float64(91), int64(4), object(30), uint8(70)\n",
      "memory usage: 61.3+ MB\n"
     ]
    }
   ],
   "source": [
    "status_dummies = pd.get_dummies(df1['status'], prefix='status',  prefix_sep='_', dummy_na=True, drop_first=False)\n",
    "df1 = pd.concat([df1, status_dummies], axis=1)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the number of languages spoken. here a blank is considered at least one language\n",
    "\n",
    "def num_languages(x):\n",
    "    split_string = x.split(', ')\n",
    "    num_langs = len(split_string)\n",
    "    return num_langs\n",
    "\n",
    "df1['num_languages'] = df1['speaks'].apply(num_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['speaks'].replace(r' \\(.*?\\)', \"\", regex=True, inplace=True)\n",
    "df1['speaks'].replace(r' ', \"\", regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_lang_list = []\n",
    "\n",
    "# for row in df1['speaks']:\n",
    "#     langs = row.split(',')\n",
    "#     for item in langs:\n",
    "#         temp_lang_list.append(item)\n",
    "\n",
    "# unique_langs = list(set(temp_lang_list))\n",
    "# sorted_langs = unique_langs.sort()\n",
    "# print(unique_langs)\n",
    "\n",
    "# code_langs = ['c++', 'lisp']\n",
    "\n",
    "def coder_check(x):\n",
    "    if 'c++' in x or 'lisp' in x: return 1\n",
    "    else: return 0\n",
    "\n",
    "df1['coder'] = df1['speaks'].apply(coder_check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
